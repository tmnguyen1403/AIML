% !TEX root = //Users/amynguyen/Projects/MathAIML/latex_files/optimization_problem.tex
\documentclass{article}
\usepackage{amsmath}
\begin{document}

Minimize $f_0(x)$\\
x is optimization variable\\
$f_0$ is an objective function\\
Optimization seeks to find the global minimum for an objective function, subject to constraints\\
Convex optimization\\
If the objective function is convex, the optimization problem is calle convex optimization\\
Example problem:
$y=x^2 + 3$\\
Note that: derivative is 0 at
\begin{itemize}
    \item local minimums
    \item local maximums
    \item global minimums
    \item global maximums
\end{itemize}
Take first derivative: $y'=2x$\\
2nd derivative test: $y''=2$\\
If the 2nd derivative is positive, it is a minimum. Otherwise, it is a maximum\\
In the context of machine learning:\\
\begin{itemize}
    \item Optimization is an iterative process
    \item The graient tells us which way to change our parameters
\end{itemize}
\textbf{Problems with optimization}
\begin{itemize}
    \item Local minimums of the objective function
    \item All kinds of different constraints
\end{itemize}
\end{document}